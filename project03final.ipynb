{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Lab notebooks are, in order:\n",
    "1. exploration.ipynb: EDA\n",
    "2. pima-model-lab-notebook.ipynb: initial model building on Pima Indians Diabetes dataset\n",
    "3. pima-fram-lab-notebook.ipynb: attempting to improve model by adding Framingham Heart Study data\n",
    "\n",
    "The big problem was that that two datasets were different not just in diabetes prevalance but also in shape of other features, resulting in a model which was performing as well as others in the scores but not making sense from a biology perspective. Age should not be negatively correlated with type II diabetes risk unless you're looking only at women who have had children and so much of what you're seeing is gestational diabetes, which will likely be a nonlinear relationship with a hump of diabetes in the 20-40 range.\n",
    "\n",
    "This notebook is a streamlined version of building a set of models for the streamlit app.\n",
    "\n",
    "# Methods\n",
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.io.sql as sqlio\n",
    "import matplotlib as plt\n",
    "import seaborn as sbn\n",
    "import numpy as np\n",
    "import psycopg2 as pg\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_args = {'host': 'localhost', \n",
    "                   'dbname': 'med_data', \n",
    "                   'port': 5432}\n",
    "connection = pg.connect(**connection_args)\n",
    "\n",
    "query = \"\"\"SELECT * FROM pima\"\"\"\n",
    "with open('tempfile.csv', 'wb') as tmpfile:\n",
    "    copy_sql = \"COPY ({query}) TO STDOUT WITH CSV {head}\".format(\n",
    "       query=query, head=\"HEADER\"\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    cursor.copy_expert(copy_sql, tmpfile)\n",
    "    tmpfile.seek(0)\n",
    "\n",
    "    pima_data = pd.read_csv('tempfile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_series = pima_data['outcome'] == 't'\n",
    "diabetes_series = pima_data['diabetes'] == 't'\n",
    "pima_data['outcome'] = outcome_series\n",
    "pima_data['diabetes'] = diabetes_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_data[['glucose', 'diabp', 'skinthickness', 'insulin']] = pima_data[['glucose', 'diabp', 'skinthickness', 'insulin']].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using subset of pima data to get best model parameters\n",
    "For the sake of consistency and minimizing user confusion, I want to use the same train-test split for all four data sets. I'm doing this before the dropna() so that I can preserve as much data as possible, but the hope is that this will result in four models where the feature set really is the biggest difference between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split consistently on all the sets\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "shuffle = ShuffleSplit(n_splits = 1, random_state = 54, test_size = 0.2)\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "for train_index, test_index in shuffle.split(pima_data):\n",
    "    train_indices = list(train_index)\n",
    "    test_indices= list(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabp</th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33</td>\n",
       "      <td>43.3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>25</td>\n",
       "      <td>36.8</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>26</td>\n",
       "      <td>38.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>27</td>\n",
       "      <td>34.2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>21</td>\n",
       "      <td>33.2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>22</td>\n",
       "      <td>44.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>28</td>\n",
       "      <td>38.1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>25</td>\n",
       "      <td>31.9</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>39</td>\n",
       "      <td>32.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>31.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age   bmi  diabp  pregnancies  diabetes\n",
       "18    33  43.3   30.0            1     False\n",
       "467   25  36.8   64.0            0     False\n",
       "87    26  38.5   68.0            2     False\n",
       "659   27  34.2   82.0            3      True\n",
       "208   21  33.2   64.0            1     False\n",
       "..   ...   ...    ...          ...       ...\n",
       "230   22  44.0   86.0            4      True\n",
       "318   28  38.1   66.0            3     False\n",
       "551   25  31.9   68.0            3     False\n",
       "756   39  32.0   90.0            7     False\n",
       "6     26  31.0   50.0            3      True\n",
       "\n",
       "[147 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ab = pima_data.loc[train_indices, ['age', 'bmi', 'diabetes']]\n",
    "train_ab.dropna()\n",
    "test_ab = pima_data.loc[test_indices, ['age', 'bmi', 'diabetes']]\n",
    "test_ab.dropna()\n",
    "\n",
    "train_abd = pima_data.loc[train_indices, ['age', 'bmi', 'diabp', 'diabetes']]\n",
    "train_abd.dropna()\n",
    "test_abd = pima_data.loc[test_indices, ['age', 'bmi', 'diabp', 'diabetes']]\n",
    "test_abd.dropna()\n",
    "\n",
    "train_abp = pima_data.loc[train_indices, ['age', 'bmi', 'pregnancies', 'diabetes']]\n",
    "train_abp.dropna()\n",
    "test_abp = pima_data.loc[test_indices, ['age', 'bmi', 'pregnancies', 'diabetes']]\n",
    "test_abp.dropna()\n",
    "\n",
    "train_abdp = pima_data.loc[train_indices, ['age', 'bmi', 'diabp', 'pregnancies', 'diabetes']]\n",
    "train_abdp.dropna()\n",
    "test_abdp = pima_data.loc[test_indices, ['age', 'bmi', 'diabp', 'pregnancies', 'diabetes']]\n",
    "test_abdp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'class_weight': ['balanced', None], 'solver': ['liblinear', 'lbfgs', 'newton-cg']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='balanced_accuracy', verbose=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'class_weight': 'balanced', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100], \n",
    "              'class_weight': ['balanced', None], \n",
    "             'solver': ['lbfgs', 'liblinear', 'newton-cg']}\n",
    "gscv = GridSearchCV(estimator = LogisticRegression(), param_grid = param_grid, scoring = 'balanced_accuracy', cv = 4, return_train_score = True)\n",
    "gscv.fit(train_ab[['age', 'bmi']], train_ab['diabetes'])\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04670707, 0.06963381]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'class_weight': 'balanced', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.fit(train_abd[['age', 'bmi', 'diabp']], train_abd['diabetes'])\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04932413,  0.06940796, -0.00104953]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'class_weight': 'balanced', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.fit(train_abp[['age', 'bmi', 'pregnancies']], train_abp['diabetes'])\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04361281, 0.09051201, 0.07484378]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'class_weight': 'balanced', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.fit(train_abdp[['age', 'bmi', 'diabp', 'pregnancies']], train_abdp['diabetes'])\n",
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04202822, 0.08520294, 0.00875516, 0.07410018]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On balance, let's go with 1.0, 'balanced', and 'liblinear'\n",
    "Given how few features there are, less regularization is likely to be necessary.\n",
    "\n",
    "'class_weight' is the parameter to tune in order to get the balance I want between false negatives and false positives. Given the relative costs of diabetes screening and a year of diabetes care, I'm aiming for around 1 false negative for every 50-100 false positives. If I were truly pitching this to an insurance company, I would want to take the time to make a slider or a dropdown that allows the client to select the desired number of false positives per false negative within an approximately 25-200 range; outside of either extreme seems intuitively unfair to either the people who miss being diagnosed or the people who get stuck with an unnecessary blood test.\n",
    "\n",
    "Liblinear takes either l1 or l2 penalties, and while I could figure out which penalty works best, I'm choosing not to. This decision is due in large part to the fact that I don't care to do all the setup necessary for creating my own grid search function that fits a scaler to each training fold. Also, the default penalty of 'l2' is the one that I tend to lean towards for smaller feature sets in any case, as it spreads the coefficients around rather than pushing small ones towards zero. This model isn't going to have the greatest scores in any case, and the benefit of deciding between the two regularization penalties is unlikely to be significant to anything for a prototype project.\n",
    "\n",
    "### Finding best class_weight to balance false negatives and false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "weights_list = [{True: 8, False: 1}, {True: 8.5, False: 1}, {True: 9, False: 1}, \n",
    "               {True: 9.5, False: 1}, {True: 10, False: 1}, \n",
    "               {True: 10.5, False: 1}, {True: 11, False: 1}, {True: 11.5, False: 1}]\n",
    "# Putting together a list of dicts that I can then put into a dataframe\n",
    "weights_results = []\n",
    "# iterate through the class_weight options\n",
    "for i in weights_list:\n",
    "    lr = LogisticRegressionCV(penalty = 'l2', scoring = 'recall', solver = 'liblinear', \n",
    "                              class_weight = i)\n",
    "    lr.fit(train_ab[['age', 'bmi']], train_ab['diabetes'])\n",
    "    # Essentially using this to get the scores and confusion matrix for the cross-validated model\n",
    "    lr_pred = lr.predict(train_ab[['age', 'bmi']])\n",
    "    lr_conf = confusion_matrix(train_ab['diabetes'], lr_pred)\n",
    "    weights_results.append({'weight': i[True], \n",
    "                           'coefficients': lr.coef_, \n",
    "                           'recall': recall_score(train_ab['diabetes'], lr_pred), \n",
    "                           'false negatives': lr_conf[1][0], \n",
    "                           'false positives': lr_conf[0][1]})\n",
    "results_df = pd.DataFrame(weights_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>coefficients</th>\n",
       "      <th>recall</th>\n",
       "      <th>false negatives</th>\n",
       "      <th>false positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>[[0.029297746471932642, 0.027076031692056225]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.5</td>\n",
       "      <td>[[0.029968144348868304, 0.02811564209481826]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>[[0.030648923563846842, 0.029047801998230083]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.5</td>\n",
       "      <td>[[0.03127237811548386, 0.02995292763066094]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>[[0.03186592911579925, 0.030811455619459707]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.5</td>\n",
       "      <td>[[0.032432539447684684, 0.03162782205952117]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.0</td>\n",
       "      <td>[[0.03297475214946724, 0.032405845468103454]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.5</td>\n",
       "      <td>[[0.03349476513811141, 0.03314883694270513]]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight                                    coefficients  recall  \\\n",
       "0     8.0  [[0.029297746471932642, 0.027076031692056225]]     1.0   \n",
       "1     8.5   [[0.029968144348868304, 0.02811564209481826]]     1.0   \n",
       "2     9.0  [[0.030648923563846842, 0.029047801998230083]]     1.0   \n",
       "3     9.5    [[0.03127237811548386, 0.02995292763066094]]     1.0   \n",
       "4    10.0   [[0.03186592911579925, 0.030811455619459707]]     1.0   \n",
       "5    10.5   [[0.032432539447684684, 0.03162782205952117]]     1.0   \n",
       "6    11.0   [[0.03297475214946724, 0.032405845468103454]]     1.0   \n",
       "7    11.5    [[0.03349476513811141, 0.03314883694270513]]     1.0   \n",
       "\n",
       "   false negatives  false positives  \n",
       "0                0              342  \n",
       "1                0              342  \n",
       "2                0              342  \n",
       "3                0              342  \n",
       "4                0              342  \n",
       "5                0              342  \n",
       "6                0              342  \n",
       "7                0              342  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "weights_list = [{True: 1, False: 1}, {True: 2, False: 1}, {True: 3, False: 1}, \n",
    "               {True: 4, False: 1}, {True: 5, False: 1}, \n",
    "               {True: 6, False: 1}, {True: 7, False: 1}, {True: 8, False: 1}]\n",
    "# Putting together a list of dicts that I can then put into a dataframe\n",
    "weights_results = []\n",
    "# iterate through the class_weight options\n",
    "for i in weights_list:\n",
    "    lr = LogisticRegressionCV(penalty = 'l2', scoring = 'recall_weighted', solver = 'liblinear', \n",
    "                              class_weight = i)\n",
    "    lr.fit(train_ab[['age', 'bmi']], train_ab['diabetes'])\n",
    "    # Essentially using this to get the scores and confusion matrix for the cross-validated model\n",
    "    lr_pred = lr.predict(train_ab[['age', 'bmi']])\n",
    "    lr_conf = confusion_matrix(train_ab['diabetes'], lr_pred)\n",
    "    weights_results.append({'weight': i[True], \n",
    "                           'coefficients': lr.coef_, \n",
    "                           'recall': recall_score(train_ab['diabetes'], lr_pred), \n",
    "                           'false negatives': lr_conf[1][0], \n",
    "                           'false positives': lr_conf[0][1]})\n",
    "results_df = pd.DataFrame(weights_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>coefficients</th>\n",
       "      <th>recall</th>\n",
       "      <th>false negatives</th>\n",
       "      <th>false positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.03695880184799391, 0.0486686769749013]]</td>\n",
       "      <td>0.547794</td>\n",
       "      <td>123</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.05756389557202192, 0.08954170895572236]]</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>46</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[[0.059568192552723956, 0.08858485011423597]]</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>16</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[[0.06132124705303733, 0.08844616240157792]]</td>\n",
       "      <td>0.959559</td>\n",
       "      <td>11</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[[0.062366302921968014, 0.08762751967234779]]</td>\n",
       "      <td>0.977941</td>\n",
       "      <td>6</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[[0.06300577815174549, 0.08657797761040381]]</td>\n",
       "      <td>0.996324</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>[[0.06352415364010106, 0.08563950681976078]]</td>\n",
       "      <td>0.996324</td>\n",
       "      <td>1</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[[0.06430213268458723, 0.08547591856246615]]</td>\n",
       "      <td>0.996324</td>\n",
       "      <td>1</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight                                   coefficients    recall  \\\n",
       "0       1    [[0.03695880184799391, 0.0486686769749013]]  0.547794   \n",
       "1       2   [[0.05756389557202192, 0.08954170895572236]]  0.830882   \n",
       "2       3  [[0.059568192552723956, 0.08858485011423597]]  0.941176   \n",
       "3       4   [[0.06132124705303733, 0.08844616240157792]]  0.959559   \n",
       "4       5  [[0.062366302921968014, 0.08762751967234779]]  0.977941   \n",
       "5       6   [[0.06300577815174549, 0.08657797761040381]]  0.996324   \n",
       "6       7   [[0.06352415364010106, 0.08563950681976078]]  0.996324   \n",
       "7       8   [[0.06430213268458723, 0.08547591856246615]]  0.996324   \n",
       "\n",
       "   false negatives  false positives  \n",
       "0              123               75  \n",
       "1               46              173  \n",
       "2               16              225  \n",
       "3               11              267  \n",
       "4                6              290  \n",
       "5                1              315  \n",
       "6                1              328  \n",
       "7                1              333  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/chesh1/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "weights_list = [{True: 2.1, False: 1}, {True: 2.2, False: 1}, {True: 2.3, False: 1}, \n",
    "               {True: 2.4, False: 1}, {True: 2.5, False: 1}, {True: 2.6, False: 1}, \n",
    "               {True: 2.7, False: 1}, {True: 2.8, False: 1}, {True: 2.9, False: 1}]\n",
    "# Putting together a list of dicts that I can then put into a dataframe\n",
    "weights_results = []\n",
    "# iterate through the class_weight options\n",
    "for i in weights_list:\n",
    "    lr = LogisticRegressionCV(penalty = 'l2', scoring = 'recall_weighted', solver = 'liblinear', \n",
    "                              class_weight = i)\n",
    "    lr.fit(train_ab[['age', 'bmi']], train_ab['diabetes'])\n",
    "    # Essentially using this to get the scores and confusion matrix for the cross-validated model\n",
    "    lr_pred = lr.predict(train_ab[['age', 'bmi']])\n",
    "    lr_conf = confusion_matrix(train_ab['diabetes'], lr_pred)\n",
    "    weights_results.append({'weight': i[True], \n",
    "                           'coefficients': lr.coef_, \n",
    "                           'recall': recall_score(train_ab['diabetes'], lr_pred), \n",
    "                           'false negatives': lr_conf[1][0], \n",
    "                           'false positives': lr_conf[0][1]})\n",
    "results_df = pd.DataFrame(weights_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>coefficients</th>\n",
       "      <th>recall</th>\n",
       "      <th>false negatives</th>\n",
       "      <th>false positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.1</td>\n",
       "      <td>[[0.05771430690364213, 0.08922862043143796]]</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>42</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>[[0.05793394313241683, 0.08910492750176296]]</td>\n",
       "      <td>0.871324</td>\n",
       "      <td>35</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.3</td>\n",
       "      <td>[[0.058213971725538105, 0.08914268481399336]]</td>\n",
       "      <td>0.893382</td>\n",
       "      <td>29</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.4</td>\n",
       "      <td>[[0.058601174501105864, 0.0894424318101029]]</td>\n",
       "      <td>0.893382</td>\n",
       "      <td>29</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>[[0.05855912094327467, 0.08880114107726125]]</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>24</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.6</td>\n",
       "      <td>[[0.05853453352910391, 0.08822991914652291]]</td>\n",
       "      <td>0.922794</td>\n",
       "      <td>21</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.7</td>\n",
       "      <td>[[0.05898878474861522, 0.0887251571020589]]</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>20</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.8</td>\n",
       "      <td>[[0.05919241311218243, 0.08868672083710233]]</td>\n",
       "      <td>0.930147</td>\n",
       "      <td>19</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.9</td>\n",
       "      <td>[[0.059689866402832026, 0.08929930256347184]]</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>17</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight                                   coefficients    recall  \\\n",
       "0     2.1   [[0.05771430690364213, 0.08922862043143796]]  0.845588   \n",
       "1     2.2   [[0.05793394313241683, 0.08910492750176296]]  0.871324   \n",
       "2     2.3  [[0.058213971725538105, 0.08914268481399336]]  0.893382   \n",
       "3     2.4   [[0.058601174501105864, 0.0894424318101029]]  0.893382   \n",
       "4     2.5   [[0.05855912094327467, 0.08880114107726125]]  0.911765   \n",
       "5     2.6   [[0.05853453352910391, 0.08822991914652291]]  0.922794   \n",
       "6     2.7    [[0.05898878474861522, 0.0887251571020589]]  0.926471   \n",
       "7     2.8   [[0.05919241311218243, 0.08868672083710233]]  0.930147   \n",
       "8     2.9  [[0.059689866402832026, 0.08929930256347184]]  0.937500   \n",
       "\n",
       "   false negatives  false positives  \n",
       "0               42              179  \n",
       "1               35              185  \n",
       "2               29              189  \n",
       "3               29              194  \n",
       "4               24              199  \n",
       "5               21              207  \n",
       "6               20              211  \n",
       "7               19              217  \n",
       "8               17              219  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model parameters found; now to generate using the whole Pima dataset\n",
    "Initially, these weight tests were run using only recall, which resulted in an understandably strong bias towards false positives. Using weighted recall, a more reasonable false positive to false negative ratio could be found without tuning the class weights down to past the tenths.\n",
    "\n",
    "Will be using LogisticRegression with penalty = 'l2', C = 0.1, class_weight = {True: 2.6, False: 1}, solver = 'liblinear' for all four models.\n",
    "\n",
    "## Generating final models\n",
    "### Age and bmi only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05273564, 0.08703538]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model_ab = LogisticRegression(penalty = 'l2', C = 1.0, class_weight = {True: 2.6, False: 1}, \n",
    "                              solver = 'liblinear')\n",
    "ab_data = pima_data[['age', 'bmi', 'diabetes']].dropna()\n",
    "model_ab.fit(ab_data[['age', 'bmi']], ab_data['diabetes'])\n",
    "with open('ab_logreg.pkl', 'wb') as fp:\n",
    "    pickle.dump(model_ab, fp)\n",
    "model_ab.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05391884, 0.08675281, 0.001567  ]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_abd = LogisticRegression(penalty = 'l2', C = 1.0, class_weight = {True: 2.6, False: 1}, \n",
    "                              solver = 'liblinear')\n",
    "abd_data = pima_data[['age', 'bmi', 'diabp', 'diabetes']].dropna()\n",
    "model_abd.fit(abd_data[['age', 'bmi', 'diabp']], abd_data['diabetes'])\n",
    "with open('abd_logreg.pkl', 'wb') as fp:\n",
    "    pickle.dump(model_abd, fp)\n",
    "model_abd.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04082995, 0.08846132, 0.07420784]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_abp = LogisticRegression(penalty = 'l2', C = 1.0, class_weight = {True: 2.6, False: 1}, \n",
    "                              solver = 'liblinear')\n",
    "abp_data = pima_data[['age', 'bmi', 'pregnancies', 'diabetes']].dropna()\n",
    "model_abp.fit(abp_data[['age', 'bmi', 'pregnancies']], abp_data['diabetes'])\n",
    "with open('abp_logreg.pkl', 'wb') as fp:\n",
    "    pickle.dump(model_abp, fp)\n",
    "model_abp.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04334931, 0.08927498, 0.00190589, 0.06907516]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_abdp = LogisticRegression(penalty = 'l2', C = 1.0, class_weight = {True: 2.6, False: 1}, \n",
    "                              solver = 'liblinear')\n",
    "abdp_data = pima_data[['age', 'bmi', 'diabp', 'pregnancies', 'diabetes']].dropna()\n",
    "model_abdp.fit(abdp_data[['age', 'bmi', 'diabp', 'pregnancies']], abdp_data['diabetes'])\n",
    "with open('abdp_logreg.pkl', 'wb') as fp:\n",
    "    pickle.dump(model_abdp, fp)\n",
    "model_abdp.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "How do these models fare against the Framingham Heart Study participants? In the pima-fram-lab-notebook.ipynb, the model trained on only the Pima data did OK on the Framingham Heart Study data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT * FROM fram\"\"\"\n",
    "with open('tempfile.csv', 'wb') as tmpfile:\n",
    "    copy_sql = \"COPY ({query}) TO STDOUT WITH CSV {head}\".format(\n",
    "       query=query, head=\"HEADER\"\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    cursor.copy_expert(copy_sql, tmpfile)\n",
    "    tmpfile.seek(0)\n",
    "\n",
    "    fram_data = pd.read_csv('tempfile.csv')\n",
    "# Calling all people with diabetes OR prediabetes as diabetic\n",
    "diabetes_series = fram_data['glucose'] >=140\n",
    "diabetes_series = diabetes_series | fram_data['diabetes'] == 1\n",
    "fram_data['diabetes'] = diabetes_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentsmoker</th>\n",
       "      <th>cigsperday</th>\n",
       "      <th>bpmeds</th>\n",
       "      <th>prevalentstroke</th>\n",
       "      <th>prevalenthyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totchol</th>\n",
       "      <th>sysbp</th>\n",
       "      <th>diabp</th>\n",
       "      <th>bmi</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>tenyearchd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>t</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>t</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  male  age  education currentsmoker  cigsperday  bpmeds  prevalentstroke  \\\n",
       "0    t   39        4.0             f         0.0     0.0                0   \n",
       "1    f   46        2.0             f         0.0     0.0                0   \n",
       "2    t   48        1.0             t        20.0     0.0                0   \n",
       "3    f   61        3.0             t        30.0     0.0                0   \n",
       "4    f   46        3.0             t        23.0     0.0                0   \n",
       "\n",
       "   prevalenthyp  diabetes  totchol  sysbp  diabp    bmi  heartrate  glucose  \\\n",
       "0             0     False    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0     False    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0     False    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1     False    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0     False    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "  tenyearchd  \n",
       "0          f  \n",
       "1          f  \n",
       "2          f  \n",
       "3          t  \n",
       "4          f  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fram_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f969afb3518>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_ab = fram_data[['age', 'bmi', 'diabetes']].dropna()\n",
    "test_data_abd = fram_data[['age', 'bmi', 'diabp', 'diabetes']].dropna()\n",
    "pred_ab = model_ab.predict(test_data_ab[['age', 'bmi']])\n",
    "conf_mat_ab = confusion_matrix(test_data_ab['diabetes'], pred_ab)\n",
    "\n",
    "sbn.heatmap(conf_mat_ab, annot = True, fmt = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's. . . not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f969b0b7c50>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ab_none = LogisticRegression(penalty = 'l2', C = 1.0, class_weight = None, \n",
    "                              solver = 'liblinear')\n",
    "ab_data = pima_data[['age', 'bmi', 'diabetes']].dropna()\n",
    "model_ab_none.fit(ab_data[['age', 'bmi']], ab_data['diabetes'])\n",
    "\n",
    "pred_ab_none = model_ab_none.predict(test_data_ab[['age', 'bmi']])\n",
    "conf_mat_ab_none = confusion_matrix(test_data_ab['diabetes'], pred_ab_none)\n",
    "sbn.heatmap(conf_mat_ab_none, annot = True, fmt = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the models were getting decent scores with weighted recall and balanced accuracy, not looking at the confusion matrix when assessing the models at the start of pima-fram-lab-notebook.ipynb was a bad choice. This model would likely perform better if it were trained on data from a subset of the population it would be used on, I'm not getting reasonable results when applying across populations.\n",
    "\n",
    "This means that while I have a model that can predict type II diabetes risk in an O'odham population, I don't have a model that can reasonably be rolled out to a wider population without having access to a dataset that's representative of the population at large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and next steps\n",
    "I don't have a model that's ready to be rolled out beyond the initial training population (O'odham peoples, in this case). A similar approach of training the model directly on the Framingham dataset might work, but for now, it makes the most sense to table that and come back to it when I'm not trying to start project 4 immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
